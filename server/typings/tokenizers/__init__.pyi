class Encoding:
    ids: list[int]

class Tokenizer:
    pre_tokenizer: object
    def __init__(self: Tokenizer, model: BPE) -> None: ...
    @staticmethod
    def from_file(path: str) -> Tokenizer: ...
    def train(self: Tokenizer, *, files: list[str], trainer: BpeTrainer) -> None: ...
    def save(self: Tokenizer, path: str) -> None: ...
    def encode(self: Tokenizer, text: str) -> Encoding: ...
    def decode(self: Tokenizer, ids: list[int]) -> str: ...
    def token_to_id(self: Tokenizer, token: str) -> int | None: ...
    def get_vocab_size(self: Tokenizer) -> int: ...

class BPE:
    def __init__(self: BPE, *, unk_token: str) -> None: ...

class Whitespace:
    def __init__(self: Whitespace) -> None: ...

class BpeTrainer:
    def __init__(
        self: BpeTrainer,
        *,
        vocab_size: int,
        min_frequency: int,
        special_tokens: list[str],
        show_progress: bool,
    ) -> None: ...
